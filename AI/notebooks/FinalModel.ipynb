{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3aa5189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75991c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DATE  person_id  bp_systolic  bp_diastolic  ACTIVITY_steps  \\\n",
      "0 2021-07-06     1487.0        115.0          73.7          2584.0   \n",
      "1 2021-07-07     1487.0        114.5          73.3          4594.0   \n",
      "2 2021-07-08     1487.0        112.5          76.1          9602.0   \n",
      "3 2021-07-09     1487.0        122.1          76.0         14121.0   \n",
      "4 2021-07-10     1487.0        120.0          64.4          7022.0   \n",
      "\n",
      "   ACTIVITY_distance  ACTIVITY_soft  ACTIVITY_moderate  ACTIVITY_intense  \\\n",
      "0             1841.0           4.67               0.02              0.00   \n",
      "1             3201.0           5.42               0.17              0.00   \n",
      "2             7011.0           5.07               1.23              0.00   \n",
      "3            11017.0           5.27               1.18              0.42   \n",
      "4             4835.0           5.77               0.18              0.00   \n",
      "\n",
      "   HR_bpm  ...  sleep_hours  sleep_efficiency_proxy  awakenings_proxy  \\\n",
      "0  73.452  ...         6.93                   0.866              0.05   \n",
      "1  73.452  ...         6.82                   0.852              0.03   \n",
      "2  73.452  ...         7.13                   0.891              0.05   \n",
      "3  73.452  ...         6.72                   0.840              0.12   \n",
      "4  73.452  ...         7.53                   0.941              0.23   \n",
      "\n",
      "   stress_level  insomnia_score  insomnia_label    month  spo2  \\\n",
      "0         0.469        0.179627               0  2021-07  97.7   \n",
      "1         0.469        0.185804               0  2021-07  98.2   \n",
      "2         0.469        0.164627               0  2021-07  98.3   \n",
      "3         0.469        0.202915               0  2021-07  98.1   \n",
      "4         0.469        0.154299               0  2021-07  98.8   \n",
      "\n",
      "   normalized_awakenings  hours_factor  \n",
      "0               0.027322       0.13375  \n",
      "1               0.016393       0.14750  \n",
      "2               0.027322       0.10875  \n",
      "3               0.065574       0.16000  \n",
      "4               0.125683       0.05875  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "Columns: ['DATE', 'person_id', 'bp_systolic', 'bp_diastolic', 'ACTIVITY_steps', 'ACTIVITY_distance', 'ACTIVITY_soft', 'ACTIVITY_moderate', 'ACTIVITY_intense', 'HR_bpm', 'SLEEP_totalsleeptime', 'SLEEP_hours', 'SLEEP_durationtosleep', 'SLEEP_wakeupduration', 'insomnia_risk', 'sleep_hours', 'sleep_efficiency_proxy', 'awakenings_proxy', 'stress_level', 'insomnia_score', 'insomnia_label', 'month', 'spo2', 'normalized_awakenings', 'hours_factor']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"final_insomnia_dataset.csv\")\n",
    "\n",
    "df[\"DATE\"] = pd.to_datetime(df[\"DATE\"])\n",
    "df = df.sort_values([\"person_id\", \"DATE\"]).reset_index(drop=True)\n",
    "\n",
    "print(df.head())\n",
    "print(\"Columns:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de14d309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing from df: []\n"
     ]
    }
   ],
   "source": [
    "target_col = \"insomnia_score\"\n",
    "\n",
    "feature_cols = [\n",
    "    \"bp_systolic\", \"bp_diastolic\",\n",
    "    \"ACTIVITY_steps\", \"ACTIVITY_distance\",\n",
    "    \"ACTIVITY_soft\", \"ACTIVITY_moderate\", \"ACTIVITY_intense\",\n",
    "    \"HR_bpm\",\n",
    "    \"sleep_hours\",\n",
    "    \"sleep_efficiency_proxy\",\n",
    "    \"awakenings_proxy\",\n",
    "    \"stress_level\",\n",
    "    \"spo2\",\n",
    "]\n",
    "\n",
    "missing = [c for c in feature_cols if c not in df.columns]\n",
    "print(\"Missing from df:\", missing)\n",
    "\n",
    "df[feature_cols] = df[feature_cols].fillna(df[feature_cols].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "527646d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (3257, 21, 13)\n",
      "y shape: (3257,)\n",
      "First 5 window end dates: ['2021-07-26T00:00:00.000000000' '2021-07-27T00:00:00.000000000'\n",
      " '2021-07-28T00:00:00.000000000' '2021-07-29T00:00:00.000000000'\n",
      " '2021-07-30T00:00:00.000000000']\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 21\n",
    "\n",
    "X_list, y_list, end_dates = [], [], []\n",
    "\n",
    "for pid, g in df.groupby(\"person_id\"):\n",
    "    g = g.sort_values(\"DATE\")\n",
    "    feats = g[feature_cols].values.astype(\"float32\")   # [T, F]\n",
    "    target = g[target_col].values.astype(\"float32\")    # [T]\n",
    "    dates = g[\"DATE\"].values\n",
    "\n",
    "    if len(g) < SEQ_LEN:\n",
    "        continue\n",
    "\n",
    "    for i in range(SEQ_LEN - 1, len(g)):\n",
    "        start = i - SEQ_LEN + 1\n",
    "        end = i\n",
    "        X_list.append(feats[start:end + 1])   # [SEQ_LEN, F]\n",
    "        y_list.append(target[end])            # score of last day\n",
    "        end_dates.append(dates[end])\n",
    "\n",
    "X = np.stack(X_list)           # [N, T, F]\n",
    "y = np.array(y_list)           # [N]\n",
    "end_dates = np.array(end_dates)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"First 5 window end dates:\", end_dates[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6688da71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows: 3257\n",
      "Train: 2605, Val: 326, Test: 326\n",
      "Train last date: 2022-03-03T00:00:00.000000000\n",
      "Val last date: 2022-03-30T00:00:00.000000000\n",
      "Test last date: 2022-07-10T00:00:00.000000000\n"
     ]
    }
   ],
   "source": [
    "sorted_idx = np.argsort(end_dates)\n",
    "X = X[sorted_idx]\n",
    "y = y[sorted_idx]\n",
    "end_dates = end_dates[sorted_idx]\n",
    "\n",
    "N = len(X)\n",
    "train_end = int(0.8 * N)\n",
    "val_end   = int(0.9 * N)\n",
    "\n",
    "train_idx = np.arange(0, train_end)\n",
    "val_idx   = np.arange(train_end, val_end)\n",
    "test_idx  = np.arange(val_end, N)\n",
    "\n",
    "print(f\"Total windows: {N}\")\n",
    "print(f\"Train: {len(train_idx)}, Val: {len(val_idx)}, Test: {len(test_idx)}\")\n",
    "print(\"Train last date:\", end_dates[train_idx][-1])\n",
    "print(\"Val last date:\",   end_dates[val_idx][-1])\n",
    "print(\"Test last date:\",  end_dates[test_idx][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb478e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[2]\n",
    "\n",
    "train_frames = X[train_idx].reshape(-1, n_features)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_frames)\n",
    "\n",
    "X_scaled = scaler.transform(X.reshape(-1, n_features)).reshape(X.shape)\n",
    "\n",
    "def make_loader(idx, batch_size=64, shuffle=True):\n",
    "    X_t = torch.from_numpy(X_scaled[idx])\n",
    "    y_t = torch.from_numpy(y[idx])\n",
    "    ds = TensorDataset(X_t, y_t)\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "train_loader = make_loader(train_idx, batch_size=64, shuffle=True)\n",
    "val_loader   = make_loader(val_idx,   batch_size=128, shuffle=False)\n",
    "test_loader  = make_loader(test_idx,  batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02732854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNLSTMRegressor(\n",
      "  (conv1): Conv1d(13, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (relu): ReLU()\n",
      "  (lstm): LSTM(32, 64, batch_first=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNNLSTMRegressor(nn.Module):\n",
    "    def __init__(self, n_features, cnn_channels=32, lstm_hidden=64,\n",
    "                 lstm_layers=1, dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=n_features,\n",
    "            out_channels=cnn_channels,\n",
    "            kernel_size=3,\n",
    "            padding=1\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=cnn_channels,\n",
    "            hidden_size=lstm_hidden,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if lstm_layers > 1 else 0.0,\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(lstm_hidden, 1)   # regression output\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T, F]\n",
    "        x = x.transpose(1, 2)              # [B, F, T]\n",
    "        x = self.relu(self.conv1(x))       # [B, C, T]\n",
    "        x = x.transpose(1, 2)              # [B, T, C]\n",
    "\n",
    "        out, _ = self.lstm(x)              # [B, T, H]\n",
    "        last = out[:, -1, :]               # [B, H]\n",
    "        last = self.dropout(last)\n",
    "        out = self.fc(last).squeeze(1)     # [B]\n",
    "        return out\n",
    "\n",
    "model = CNNLSTMRegressor(n_features=n_features).to(DEVICE)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87da3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train MSE: 0.0092 | Train MAE: 0.0715 | Val MSE: 0.0030 | Val MAE: 0.0441\n",
      "Epoch 02 | Train MSE: 0.0031 | Train MAE: 0.0427 | Val MSE: 0.0010 | Val MAE: 0.0253\n",
      "Epoch 03 | Train MSE: 0.0017 | Train MAE: 0.0328 | Val MSE: 0.0006 | Val MAE: 0.0192\n",
      "Epoch 04 | Train MSE: 0.0013 | Train MAE: 0.0283 | Val MSE: 0.0004 | Val MAE: 0.0155\n",
      "Epoch 05 | Train MSE: 0.0011 | Train MAE: 0.0250 | Val MSE: 0.0003 | Val MAE: 0.0138\n",
      "Epoch 06 | Train MSE: 0.0009 | Train MAE: 0.0233 | Val MSE: 0.0002 | Val MAE: 0.0129\n",
      "Epoch 07 | Train MSE: 0.0008 | Train MAE: 0.0217 | Val MSE: 0.0002 | Val MAE: 0.0106\n",
      "Epoch 08 | Train MSE: 0.0007 | Train MAE: 0.0207 | Val MSE: 0.0002 | Val MAE: 0.0099\n",
      "Epoch 09 | Train MSE: 0.0006 | Train MAE: 0.0198 | Val MSE: 0.0001 | Val MAE: 0.0097\n",
      "Epoch 10 | Train MSE: 0.0006 | Train MAE: 0.0186 | Val MSE: 0.0001 | Val MAE: 0.0089\n",
      "Epoch 11 | Train MSE: 0.0006 | Train MAE: 0.0182 | Val MSE: 0.0001 | Val MAE: 0.0092\n",
      "Epoch 12 | Train MSE: 0.0006 | Train MAE: 0.0180 | Val MSE: 0.0001 | Val MAE: 0.0085\n",
      "Epoch 13 | Train MSE: 0.0005 | Train MAE: 0.0178 | Val MSE: 0.0001 | Val MAE: 0.0074\n",
      "Epoch 14 | Train MSE: 0.0005 | Train MAE: 0.0169 | Val MSE: 0.0001 | Val MAE: 0.0073\n",
      "Epoch 15 | Train MSE: 0.0005 | Train MAE: 0.0164 | Val MSE: 0.0001 | Val MAE: 0.0069\n",
      "Epoch 16 | Train MSE: 0.0004 | Train MAE: 0.0160 | Val MSE: 0.0001 | Val MAE: 0.0076\n",
      "Epoch 17 | Train MSE: 0.0004 | Train MAE: 0.0156 | Val MSE: 0.0001 | Val MAE: 0.0063\n",
      "Epoch 18 | Train MSE: 0.0004 | Train MAE: 0.0150 | Val MSE: 0.0001 | Val MAE: 0.0067\n",
      "Epoch 19 | Train MSE: 0.0004 | Train MAE: 0.0148 | Val MSE: 0.0001 | Val MAE: 0.0062\n",
      "Epoch 20 | Train MSE: 0.0004 | Train MAE: 0.0149 | Val MSE: 0.0001 | Val MAE: 0.0063\n",
      "Epoch 21 | Train MSE: 0.0004 | Train MAE: 0.0141 | Val MSE: 0.0000 | Val MAE: 0.0057\n",
      "Epoch 22 | Train MSE: 0.0003 | Train MAE: 0.0136 | Val MSE: 0.0001 | Val MAE: 0.0063\n",
      "Epoch 23 | Train MSE: 0.0003 | Train MAE: 0.0131 | Val MSE: 0.0000 | Val MAE: 0.0055\n",
      "Epoch 24 | Train MSE: 0.0003 | Train MAE: 0.0131 | Val MSE: 0.0000 | Val MAE: 0.0054\n",
      "Epoch 25 | Train MSE: 0.0003 | Train MAE: 0.0127 | Val MSE: 0.0001 | Val MAE: 0.0059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_mae  = 0.0\n",
    "    total_n    = 0\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(DEVICE)\n",
    "        yb = yb.to(DEVICE)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        mae  = torch.mean(torch.abs(preds - yb))\n",
    "\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        n = xb.size(0)\n",
    "        total_loss += loss.item() * n\n",
    "        total_mae  += mae.item() * n\n",
    "        total_n    += n\n",
    "\n",
    "    return total_loss / total_n, total_mae / total_n\n",
    "\n",
    "EPOCHS = 25\n",
    "best_val_loss = float(\"inf\")\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_mae = run_epoch(train_loader, train=True)\n",
    "    val_loss,   val_mae   = run_epoch(val_loader,   train=False)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_state = model.state_dict()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"Train MSE: {train_loss:.4f} | Train MAE: {train_mae:.4f} | \"\n",
    "        f\"Val MSE: {val_loss:.4f} | Val MAE: {val_mae:.4f}\"\n",
    "    )\n",
    "\n",
    "model.load_state_dict(best_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e7b50e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.0001 | Test MAE: 0.0076\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss, test_mae = run_epoch(test_loader, train=False)\n",
    "print(f\"Test MSE: {test_loss:.4f} | Test MAE: {test_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe3fcdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: insomnia_cnn_lstm_model.pt\n"
     ]
    }
   ],
   "source": [
    "# Save entire model state dict\n",
    "model_path = \"insomnia_cnn_lstm_model.pt\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "print(\"Model saved to:\", model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09b11920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved to: insomnia_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "scaler_path = \"insomnia_scaler.pkl\"\n",
    "with open(scaler_path, \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"Scaler saved to:\", scaler_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
